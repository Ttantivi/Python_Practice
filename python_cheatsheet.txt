Python Cheat sheet

List Slicing:

list[3:5], only prints 3 and 4.
[start: end], [inclusive, exclusive]

list[:5] start to 5
list[5:] 5 to end

Delete from list:
del(list[index])

Assigning new list, and not just reference
x = [1, 2, 3]
y = list(x)
jeffre d'andria

Methods
this is the .stuff in a python object
fam.index("stuff")

Importing packages
import numpy as np
from numpy import array
import matplotlib.pyplot as plt

bmi > 23 will give a list of true and falses
bmi[bmi > 23] give you stuff that's > 23

Attributes
array.shape # notice how there isn't any (), since it is an attribute.


Plots
import matplotlib.pyplot as plt
plt.plot(year, pop)
plt.xlabel('')
plt.ylabel('')
plt.title('')
plt.grid(True)

plt.show()

plt.scatter(x = gdp_cap, y = life_exp, s = np.array(pop) * 2, c = col,
alpha = 0.8)


Dictionaires
world = {"afghanistan":30.55, "albania":2.77}
Key value pairs

---------
# Create the years and durations lists
years = range(2011, 2020)
durations = [103, 101, 99, 100, 100, 95, 95, 96, 93, 90]

# Create a dictionary with the two lists
movie_dict = {'years':years, 'durations':durations}

# Print the dictionary
movie_dict
---------

adding new stuff: dict['key'] = value
del(world['key'])

check if something is in there
'value' in dict

Pandas
df = pd.read_csv('path',  index_col = 0 )
pd.DataFrame(dict)
cars.index = row_labels

brics['country'] # this will return a series
brics[['country']] # this will return a one column data frame

loc # label based
iloc # integer position-based

brics.loc[['RU']] # get row based on label
brics.iloc[[1]] # get row based on index

brics.iloc[[:, [0,1]] # get all rows and columns 0 and 1

filter for row then print column
cars.loc[['RU, 'MOR'], ['Country', 'drives_right']]

subsetting dataframe
brics[brics['area'] > 8]
brics[np.logical_and(brics['area'] > 8), brics['area' < 10]]

Numpy logical
np.logical_and()
np.logical_or()
np.logical_not()


if condition:
     expression
elif x > y:
     expression
else:

while condition:
     expression

for i in array:
     print(i)

for index, height in enumerate(fam):
     index # this is an index that keeps count
     height # this is the actual values of the array

# printing for dictionary
for key, value in dict.items():
     key # key of dict
     value # value of dict

# printing over all elements of np array
for val in np.nditer(array):
	print val

-------------------------------
##### loading csv #####
df = pd.read_csv('csvname.csv', parse_dates[''], index_col='')

df.to_csv('name.csv')

##### Creating a dataframe #####
my_dict = {'key1':value1, 'key2':value2}

list of dictionaries = row by row
dictionary of lists = column by column

pd.DataFrame(stuff)

# now for pandas data frame
# iterate over rows
for lab, row in df.iterrows():
     df.loc[lab, 'name_length'] = len(row['column'])

df['name_length] = df['country'].apply(len)
cars['COUNTRY'] = cars['country'].apply(str.upper)

# summary stuff
df.info() # columns names, type, number of missing values.
df.shape # rows and columns
df.desbribe() # summary statistics
df.values # data values of in 2 dimensional numpy arrays
df.columns # colum nnames
df.index # rows

# Sorting
df.sort_values("column_name", ascending=True)
df.sort_values(["column_name 1", "column_name 2"], ascending=[True, True])

# Subsetting columns
df["column_name"]
df[['column 1', 'column 2']]

# subsetting rows
df[df['height'] > 50]
df[df['breed'] == 'labs']
df[ (df['height'] > 50) & (df['breed'] == 'labs')]
df[df['color'].isin(['Black', 'Brown'])]

# creating new columns
df['meters'] = df['cm']/100

##### Data Aggregation #####
df.['col'].mean(), median, mode, min, max, var, std, sum, quantile
df.['col'].agg([pct30, pct40])
df.['col'].cumsum()

##### Counting #####
df.drop_duplicates(subset="name") # dropping dupluicates based on columns. Get unique values in columns
df.drop_duplicates(subset=['name', 'breed']) # dropping duplicate pairs
df_unique['col'].value_counts()
df_unique['col'].value_counts(sort=True)
df_unique['col'].value_counts(normalize=True)


##### Grouped Summary Statistics #####
dogs.groupby('color')['weight_kg'].mean()
dogs.groupby('[color', 'breed'])[['weight_kg', 'height_cm]].agg([min, max, sum])

df.groupby('col').size() # count of each group.

##### Group by to pivot #####
dogs.pivot_table(values ='weight_kg', index='color', aggfunc=[np.mean, np.median]) # index is the group, values is  the aggregation.

dogs.pivot_table(values ='weight_kg', index='color', columns='breed') # values are the weights, index is rows, columns are columns. 
     fill_value=0 # zeroes instead of NaN's
     margins=True # last row and column will contain means of columns or row, not counting the zeroes.

##### Indexing #####
dogs_ind = dogs.set_index('name') # setting a column as the index
dogs_ind.reset_index() # removing an index
dogs_ind.reset_index(drop=True) # gets rid of the column

dogs_in = dogs.set_index(['breed', 'color'])

dogs.sort_index() # ascending order, default
dogs.sort_index(level=['color', breed'], ascending[True, False])

##### Slicing #####
sort the index before slicing
dogs_srt.loc['Chow Chow":"Poodle"] # final value is included
dogs_srt.loc['first index outer':'last index outer', 'inner':'last inner']

dogs_srt.loc[:, 'name':'height_cm'] # slicing columns and keeping all rows.

dogs.iloc[2:5, 1:4] # slicing by row and column numbers

# Subset rows from Pakistan, Lahore to Russia, Moscow
print(temperatures_srt.loc[('Pakistan', 'Lahore'):('Russia', 'Moscow')])

# Filtering for column A, but only keeping column B.
avocados[avocados['type']=='conventional'][['avg_price']]


##### Aggregating pivot tables #####
dogs_height_by_breed_vs_color.mean(axis = 'index') # summary statistic for each column
dogs_height_by_breed_vs_color.mean(axis = 'columns') # summary statistic for each row


##### Matplotlib stuff #####
# histogram
import matplotlib.pyplot as plt
df['col'].hist(alpha = 0.7, bins = x) # create a histogram
plt.show

alpha = opacity

# barplots
do a group by, then take the mean
avg_weight_by_breed.plot(kind='bar', title='asdf')
plt.show

# lineplots
sully.plt(x='date', y='weight' kind = 'line', rot = 45)
plt.show

sully.plt(x='date', y='weight' kind = 'line', rot = 45)
plt.show

# scatter
dog_pack.plt(x='height', y='weight', kind='scatter)
plt.show

plt.legend([])


##### missing values #####
df.isna() # boolean values if it's missing or not.
df.isna().any() # if there's any missing values in a column
df.isna().sum() # number of missing data by column

df.dropna() # dropping rows
df.fillna(0) # fills values with 0

# keep only nas
df[df.isna()]

-------------------------------
# random numbers stuff
np.random.seed(123)
np.random.rand()
np.random.ranint(0,2) # randomly between 0 or 1
np.random.rand()



----------------------------------------------------------------------------------------------------------------------------
Join Pandas dataframes

##### inner join #####
joined_df = df1.merge(df2, on='key', suffixes=('_suffix1', '_suffix2'))

suffix if table with same name

joined_df = df1.merge(df2, on=['key1', 'key2'], suffixes=('_suffix1', '_suffix2')) # merge on multiple columns in case of dups

# left or right join
df1.merge(df2, on='id', how='left')

df1.merge(df2, how='right', left_on='id1', right_on='id2) # if id names are not the same in tables.

# self join

##### merging on indexs #####

movies.merge(movie_to_genres, left_on='id', left_index=True, right_on='movie_id', right_index=True) # make sure index is true

##### Filtering Join #####
Filter table 1 based on the values of table 2

Semi-joins
 * returns the intersection, similar to an  inner join
 * returns only columns from the left table and not the right
 * no duplicates

merged_df = df1.merge(df2, on='id')
df1[df1['id].isin(merged_df['id'])]

Anti-join
 * opposite of semi join

merged_df = df1.merge(df2, on='gid', how='left', indicator=True) # indicator _merge gives (both, left_only, right_only) or source of each row.
id_list = merged_df.loc[merged_df['_merge'] == 'left_only', 'gid']
df1[df1['id'].isin(id_list)]

##### Concatonate Dataframes Vertically #####
pd.concat([df1, df2, df3], ignore_index = True, sort = True) # sorting column names

pd.concat([df1, df2], join='inner') # same columns

# Group the invoices by the index keys and find avg of the total column
avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})


##### verifying integrity #####
df1.merge(df2, on='id', validate='one_to_one')

pd.concat([df1,df2], verify_integrity=True) # this will throw an error when there's duplicate rows.

##### pd.merge_ordered() #####
For time series data
pd.merge_ordered(df1, df2, on='date', suffixes=['_df1', '_df2'])

If there's missing data, we can do forward fill. Fill missing row with previous value.
pd.merge_ordered(df1, df2, on='date', suffixes=['_df1', '_df2'], fill_method='ffill')

left_on, right_on when diff id

##### pd.merge_asof() #####
 * match on the nearest key column and not exact matches.
 * ! merged on columns must be sorted !! 

pd.merge_asof(df1, df2, on='date_time', suffixes=('_df1', '_df2'))

##### .query() #####
df1.query('col1 > 90 & col2 < 140')

df1.query('col1 == "hello" ')

##### .melt() #####
unpivots dataset
 * column names bcome row values.
 * adn the values those columns, then now correspond to the rows of the unpivoted columns.

df.melt(id_vars=[], value_vars=['col1', 'col2'], var_name['name variable column (old col)'], value_name=['name of values of unpivoted col'])

value_vars # controls which columns are melted

----------------------------------------------------------------------------------------------------------------------------
Python Stats Stuff
.agg([np.mean,  np.median])

np.std()
np.var()
np.quantile(col, 0.5) # where 0.5 is the quantile.
plt.boxplot(col)
np.linspace(start, stop, num) # num = intervals

iqr = 75th - 25th quartile
from scipy.stats import iqr
iqr(col)

col.describe # count, mean, std, min, 25 50 75 quarts, max

outliers. Less than Q1 - 1.5*IQR
             Greater than Q3 + 1.5*IQR

np.random.seed()

df.sample(n=x, replace =True)


scipy stuff
from scipy.stats import uniform, binom, norm, poisson, expon, 

np.round(uniform.rvs(loc=0, scale=10, size=1000)) # sample from 0 to 10
uniform.cdf(7,0,12) # sample of 7 from 0 to 12

binom.rvs(# of coins, p, size = n)
binom.pmf(value, n, p) # gets the probability of value
binom.cdf(value, n, p) # gets the probability of 0 to value.

norm.rvs(loc=mean, scale=std_dev, size=10)
norm.cdf(value, mean, sd)
norm.ppf(percentage, mean, sd) # what actual say value is at the percentage

poisson.rvs(8, size=10) # lambda = 8, sample size 10
poisson.pmf(5, 8) # where 8 is lambda. Get prob of 5 
poisson.cdf(5, 8) # lambda = 8, prob less that 5.

expon.cdf(value, scale) # where scale is lambda


import seaborn as sns
sns.lmplot(x=, y=, data=, ci = None)
sns.scatterplot(x, y, data)
plt.show()


correlations:
df['x'].corr(df['y'])

transformations
np.log(df['col'])
sqrt()


----------------------------------------------------------------------------------------
Matplot stuff

import matplotlib.pyplot as plt
fig, ax = plt.subplots()

fig is container that holds stuff on page
ax is what holds the data

ax.plot(x, y)
plt.show()

Can add multiple plots on one by calling ax again.


syntax:
ax.plot(x,y,marker='o', linestyle='--', color=r) # marker is marker at points. Can even do none.
ax.set_xlabel('Time')
ax.set_ylabel('Values')
ax.set_title('Title')
ax.tick_params('y', colors='blue')

##### grid of plots #####
fig, ax = plt.subplots(row,columns, sharey=True) # row by column of plots

now ax is an array of objects

ax[0,0].plot(...)

##### for time series #####
ax.plot(df.index, df['col'])

where index is a datetime datatype


##### twin axes #####
ax2 = ax.twinx() # meaing same x axis, but separate y-axes
ax2.plot(...)
ax2.set_ylabel('asdf', color='')
ax.tick_params('y', colors='red')

##### Annotations #####
adding arrows in plot

ax.annotate('annotation', xy = (xposit,yposit), xytext(), arrowprops={'arrowstyle':'->', 'color':'gray'})
# xytext is the position of the text
# arrowprops={} dictionary of arrow properties





