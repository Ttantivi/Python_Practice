{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoids</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Dilution</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0      1    14.23       1.71  2.43               15.6        127   \n",
       "1      1    13.20       1.78  2.14               11.2        100   \n",
       "2      1    13.16       2.36  2.67               18.6        101   \n",
       "3      1    14.37       1.95  2.50               16.8        113   \n",
       "4      1    13.24       2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoids  Proanthocyanins  Color   Hue  \\\n",
       "0           2.80        3.06           0.28             2.29   5.64  1.04   \n",
       "1           2.65        2.76           0.26             1.28   4.38  1.05   \n",
       "2           2.80        3.24           0.30             2.81   5.68  1.03   \n",
       "3           3.85        3.49           0.24             2.18   7.80  0.86   \n",
       "4           2.80        2.69           0.39             1.82   4.32  1.04   \n",
       "\n",
       "   Dilution  Proline  \n",
       "0      3.92     1065  \n",
       "1      3.40     1050  \n",
       "2      3.17     1185  \n",
       "3      3.45     1480  \n",
       "4      2.93      735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading in data\n",
    "file_path = os.path.join(\"data\", \"wine.data\")\n",
    "column_names = ['class', 'Alcohol', 'Malicacid', 'Ash',\n",
    "                'Alcalinity_of_ash', 'Magnesium', 'Total_phenols',\n",
    "                'Flavanoids', 'Nonflavanoids',\n",
    "                'Proanthocyanins', 'Color', 'Hue',\n",
    "                'Dilution', 'Proline'] \n",
    "\n",
    "data_df = pd.read_csv(file_path, sep = ',', names = column_names)\n",
    "\n",
    "data_df.head(n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting variables from dataframe\n",
    "y = data_df['class']\n",
    "X = data_df.drop('class', axis = 1)\n",
    "\n",
    "# splitting into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 230)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA model:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Create an LDA object\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model\n",
    "lda_model = lda.fit(X_train, y_train)\n",
    "\n",
    "# predicting with the model\n",
    "predictions_lda = lda_model.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy_lda = accuracy_score(y_test, predictions_lda)\n",
    "\n",
    "print('Accuracy of LDA model: ', accuracy_lda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression model:  0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timtan/opt/anaconda3/envs/stat254-proj/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create a Logistic Regression object\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "log_reg_model = log_reg.fit(X_train, y_train)\n",
    "\n",
    "# predicting with the model\n",
    "predictions_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "# calculating accuracy\n",
    "accuracy_log_reg = accuracy_score(y_test, predictions_log_reg)\n",
    "\n",
    "print('Accuracy of Logistic regression model: ', accuracy_log_reg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning usually indicates that the optimization algorithm (in this case, lbfgs) was unable to find the optimal solution within the specified number of iterations.\n",
    "\n",
    "lbfgs is an optimization algorithm used in the training process of some machine learning models, including the LogisticRegression model in scikit-learn. It tries to find the model parameters that minimize the cost function.\n",
    "\n",
    "When you see this warning, it means that the lbfgs algorithm reached the maximum number of iterations set by the max_iter parameter (default is 100 for LogisticRegression) before it found a solution that it considers optimal. As a result, the solution that you get might not be the best possible solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat254-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
